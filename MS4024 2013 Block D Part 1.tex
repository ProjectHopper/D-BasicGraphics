\documentclass[a4paper,12pt]{article}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{eurosym}
\usepackage{vmargin}
\usepackage{amsmath}
\usepackage{graphics}
\usepackage{epsfig}
\usepackage{subfigure}
\usepackage{fancyhdr}
%\usepackage{listings}
\usepackage{framed}
\usepackage{graphicx}

\setcounter{MaxMatrixCols}{10}
%TCIDATA{OutputFilter=LATEX.DLL}
%TCIDATA{Version=5.00.0.2570}
%TCIDATA{<META NAME="SaveForMode" CONTENT="1">}
%TCIDATA{LastRevised=Wednesday, February 23, 2011 13:24:34}
%TCIDATA{<META NAME="GraphicsSave" CONTENT="32">}
%TCIDATA{Language=American English}

\pagestyle{fancy}
\setmarginsrb{20mm}{0mm}{20mm}{25mm}{12mm}{11mm}{0mm}{11mm}
\lhead{Rstats} \rhead{Kevin O'Brien}
\chead{Introduction to R Programming}
%\input{tcilatex}

\begin{document}
	
	\tableofcontents
	\newpage
	\section{The R Programming Language}
	
	The R Programming Language is a statistical , data analysis , etc
	
	R is a free software environment for statistical computing and graphics.
	
	\section{Writing R scripts}
	Editing your R script ``R Editor".
	\begin{itemize}
		\item On the menu of the R console, click on file.
		\item Select open script or new script as appropriate.
		\item Navigate to your working directory and select your \texttt{.R} file
		\item A new dialogue box ``\texttt{the R editor}" will open up.
		\item Input or select code you wish to compile.
		\item To compile this code, highlight it. Click the edit button on the menu.
		\item Select either ``Run Line" or ``Run Selection or All".
		\item Your code should now compile.
		\item To save your code, clink on ``file" and then ``\texttt{save as}".
		\item Save the file with the ``\texttt{.R}" extension to your working directory.
	\end{itemize}
	
	\section{Vector types}
	\texttt{R} operates on named data structures. The simplest such structure is the
	vector, which is a single entity consisting of an ordered collection of
	Numbers or characters.
	
	\begin{itemize}
		\item Numeric vectors
		\item Character vectors
		\item Logical vectors
		\item (also complex number vectors and colour vectors)
	\end{itemize}
	
	To create a vector, use the assignment operator and the concatenate function.
	For numeric vectors, the values are simply numbers.
	
	\begin{verbatim}
	># week8.r
	>NumVec<-c(10.4,5.6,3.1,6.4)
	\end{verbatim}
	
	Alternatively we can use the \texttt{assign()} command
	
	For character vectors, the values are simply characters, specified with
	quotation marks.A logical vectors is a vector whose elements are TRUE, FALSE or NA
	
	\begin{verbatim}
	>CharVec<-c(``blue", ``green", ``yellow")
	>LogVec<-c(TRUE, FALSE)
	\end{verbatim}
	
	\section{Graphical data entry interface}
	
	\texttt{Data.entry()} is a useful  command for inputting or editing data sets. Any
	changes are saved automatically (i.e. dont need to use the assignment
	operator). We can also used the \texttt{edit()} command, which calls the \texttt{R Editor}.
	
	\begin{verbatim}
	>data.entry(NumVec)
	>NumVec <- edit(NumVec)
	\end{verbatim}
	
	Another method of creating vectors is to use the following
	\begin{verbatim}
	numeric (length = n)
	character (length = n)
	logical (length = n)
	\end{verbatim}
	These commands create empty vectors, of the appropriate kind, of length $n$. You can then use the graphical data entry interface to populate your data sets.
	
	\subsubsection{Accessing specified elements of a vector}
	
	The $n$th element of vector ``Vec" can be accessed by specifying its index when
	calling ``Vec".
	\begin{verbatim}>Vec[n]
	\end{verbatim}
	A sequence of  elements of vector ``Vec" can be accessed by specifying its index
	when calling ``Vec".
	\begin{verbatim}>Vec[l:u]
	\end{verbatim}
	Omitting and deleting the $n$th element of vector ``Vec"
	\begin{verbatim}
	>Vec[-n]
	>Vec <- Vec[-n]
	\end{verbatim}
	
	%\subsection{Reading data}
	
	
	\subsection{inputting data}
	Concatenation
	
	\subsection{using help}
	
	\begin{framed}
		\begin{verbatim}
		?mean
		\end{verbatim}
	\end{framed}
	
	%\subsection{Adding comments}
	
	
	\newpage
	\section{Managing Precision}
	\begin{itemize}
		\item \texttt{floor()} - 
		\item \texttt{ceiling()} - 
		\item \texttt{round()} - 
		\item \texttt{as.integer()} -
	\end{itemize}
	
	\begin{framed}
		\begin{verbatim}
		> pi
		[1] 3.141593
		> floor(pi)
		[1] 3
		> ceiling(pi)
		[1] 4
		> round(pi,3)
		[1] 3.142
		> as.integer(pi)
		[1] 3
		\end{verbatim}
	\end{framed}
	
	\section{Basic Operations}
	\subsection{Complex numbers}
	\subsection{Trigonometric functions}
	\section{Matrices}
	
	%\end{document}
	
	%============================================================================================== %
	\newpage
	\subsection{exponentials, powers and logarithms}
	\large
	\begin{framed}
		\begin{verbatim}
		>x^y
		>exp(x)
		>log(x)
		>log(y)
		#determining the square root of x
		>sqrt(x)
		\end{verbatim}
	\end{framed}
	
	%============================================================================================== %
	
	\subsection{Packages}
	The capabilities of \texttt{R} are extended through user-submitted packages, which allow specialized statistical techniques, graphical devices, as well as and
	import/export capabilities to many external data formats.
	
	
	
	\large
	\subsection{vectors}
	\large
	\begin{framed}
		\begin{verbatim}
		R handles vector objects quite easily and intuitively.
		
		> x<-c(1,3,2,10,5)    #create a vector x with 5 components
		> x
		[1]  1  3  2 10  5
		> y<-1:5              #create a vector of consecutive integers
		> y
		[1] 1 2 3 4 5
		> y+2                 #scalar addition
		[1] 3 4 5 6 7
		> 2*y                 #scalar multiplication
		[1]  2  4  6  8 10
		> y^2                 #raise each component to the second power
		[1]  1  4  9 16 25
		> 2^y                 #raise 2 to the first through fifth power
		[1]  2  4  8 16 32
		> y                   #y itself has not been unchanged
		[1] 1 2 3 4 5
		> y<-y*2
		> y                   #it is now changed
		[1]  2  4  6  8 10
		\end{verbatim}
	\end{framed}
	\large
	
	\subsubsection{Misc}
	\texttt{seq()} and \texttt{rep()} are useful commands for constructing vectors with a certain pattern.
	
	%\end{document}
	
	\subsection{Matrices}
	A matrix refers to a numeric array of rows and columns.
	
	One of the easiest ways to create a matrix is to combine vectors of equal
	length using cbind(), meaning "column bind". Alternatively one can use rbind(), meaning ``row bind".
	
	
	\subsubsection{Matrices Inversion}
	\subsubsection{Matrices Multiplication}
	
	
	\subsection{Data frame}
	A Data frame is
	\newpage
	
	%------------------------------------------------------------------------------------------------%
	
	\chapter{Descriptive Statistics}
	
	\section{Basic Statistics}
	
	\large
	\begin{framed}
		\begin{verbatim}
		> X=c(1,4,5,7,8,9,5,8,9)
		> mean(X);median(X)       #mean and median of vector
		[1] 6.222222
		[2] 7
		> sd(X)                   #standard deviation of Vector
		[1] 2.682246
		> length(X)               #sample size of vector
		[1] 9
		> sum(X)
		[1] 56
		> X^2
		[1]  1 16 25 49 64 81 25 64 81
		> rev(X)
		[1] 9 8 5 9 8 7 5 4 1
		> sort(X)                 #items in ascending order
		[1] 1 4 5 5 7 8 8 9 9
		> X[1:5]
		[1] 1 4 5 7 8
		\end{verbatim}
	\end{framed}
	\large
	
	
	\section{Summary Statistics}
	The \texttt{R} command \texttt{summary()} returns a summary statistics for a simple dataset.
	The \texttt{R} command \texttt{fivenum()} returns a summary statistics for a simple dataset, but without the mean.
	Also, the quartiles are computed a different way.
	
	\large
	\begin{framed}
		\begin{verbatim}
		> summary(mtcars$mpg)
		Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
		10.40   15.43   19.20   20.09   22.80   33.90 
		>
		> fivenum(mtcars$mpg)
		[1] 10.40 15.35 19.20 22.80 33.90
		\end{verbatim}
	\end{framed}
	\large
	
	
	
	
	\section{Bivariate Data}
	\large \begin{framed}
		\begin{verbatim}
		> Y=mtcars$mpg
		> X=mtcars$wt
		>
		> cor(X,Y)          #Correlation
		[1] -0.8676594
		>
		> cov(X,Y)          #Covariance
		[1] -5.116685
		\end{verbatim}
	\end{framed}\large
	
	
	\section{Histograms}
	Histograms can be created using the \texttt{hist()} command.
	To create a histogram of the car weights from the Cars93 data set
	\large
	\begin{framed}
		\begin{verbatim}
		hist(mtcars$mpg, main="Histogram of MPG (Data: MTCARS) ")
		\end{verbatim}
	\end{framed}\large
	\texttt{R} automatically chooses the number and width of the bars. We can
	change this by specifying the location of the break points.
	\large
	\begin{framed}
		\begin{verbatim}hist(Cars93$Weight, breaks=c(1500, 2050, 2300, 2350, 2400,
		2500, 3000, 3500, 3570, 4000, 4500), xlab="Weight",
		main="Histogram of Weight")
		\end{verbatim}
	\end{framed}\large
	
	
	
	\section{Boxplot}
	Boxplots can be used to identify outliers.
	
	By default, the \texttt{boxplot()} command sets the orientation as vertical. By adding the argument \texttt{horizontal=TRUE}, the orientation can be changed to horizontal.
	\large
	\begin{framed}
		\begin{verbatim}
		boxplot(mtcars$mpg, horizontal=TRUE, xlab="Miles Per Gallon",
		main="Boxplot of MPG")
		\end{verbatim}
	\end{framed}\large
	
	\begin{figure}
		% Requires \usepackage{graphicx}
		\includegraphics[scale=0.4]{MTCARSboxplot.png}\\
		\caption{Boxplot}\label{boxplot}
	\end{figure}
	
	
	
	\newpage
	\chapter{Advanced R code}
	\section{Data frame}
	A Data frame is
	\subsection{Merging Data frames}
	
	\section{Functions}
	Syntax to define functions
	
	\begin{framed}
		\begin{verbatim}
		myfct <- function(arg1, arg2, ...) { function_body }
		\end{verbatim}
	\end{framed}
	The value returned by a function is the value of the function body, which is usually an unassigned final expression, e.g.: return()
	
	Syntax to call functions
	\begin{framed}
		\begin{verbatim}
		myfct(arg1=..., arg2=...)
		\end{verbatim}
	\end{framed}
	
	
	\section{Time and Date}
	It is useful . The length of time a program takes is interesting.
	
	
	\begin{framed}
		\begin{verbatim}
		date() # returns the current system date and time
		\end{verbatim}
	\end{framed}
	
	
	\section{The Apply family}
	
	Sometimes want to apply a function to each element of a
	vector/data frame/list/array.
	\\
	Four members: lapply, sapply, tapply, apply
	\\
	lapply: takes any structure and gives a list of results (hence
	the `l')
	\\
	sapply: like lapply, but tries to simplify the result to a
	vector or matrix if possible (hence the `s')
	\\
	apply: only used for arrays/matrices
	\\
	tapply: allows you to create tables (hence the `t') of values
	from subgroups defined by one or more factors.
	\newpage
	\chapter{Data Visualization}
	\section{Plots}
	This section is an introduction for producing simple graphs with
	the R Programming Language.
	\begin{itemize}
		\item Line Charts  \item Bar Charts \item Histograms \item Pie
		Charts \item Dotcharts
	\end{itemize}
	
	\subsubsection{Comparison of variances}
	
	
	Even though it is possible in R to perform the two-sample t test without
	the assumption that the variances are the same, you may still be interested
	in testing that assumption, and R provides the var.test function for that
	purpose, implementing an F test on the ratio of the group variances. It is
	called the same way as \texttt{t.test}:.
	\begin{verbatim}
	> var.test(expend~stature)
	\end{verbatim}
	\begin{itemize}
		\item
		\item
	\end{itemize}
	\large \begin{verbatim}
	> code here
	\end{verbatim}\large
	
	
	\subsection{ Charts}
	
	\begin{framed}
		\begin{verbatim}
		# Define 2 vectors cars <- c(1, 3, 6, 4, 9) trucks <- c(2, 5, 4,
		5, 12)
		
		# Calculate range from 0 to max value of cars and trucks g_range
		<- range(0, cars, trucks)
		
		# Graph autos using y axis that ranges from 0 to max # value in
		cars or trucks vector.  Turn off axes and # annotations (axis
		labels) so we can specify them ourself plot(cars, type="o",
		col="blue", ylim=g_range,
		axes=FALSE, ann=FALSE)
		
		# Make x axis using Mon-Fri labels axis(1, at=1:5,
		lab=c("Mon","Tue","Wed","Thu","Fri"))
		
		# Make y axis with horizontal labels that display ticks at # every
		4 marks. 4*0:g_range[2] is equivalent to c(0,4,8,12). axis(2,
		las=1, at=4*0:g_range[2])
		
		# Create box around plot box()
		
		# Graph trucks with red dashed line and square points
		lines(trucks, type="o", pch=22, lty=2, col="red")
		
		# Create a title with a red, bold/italic font title(main="Autos",
		col.main="red", font.main=4)
		
		# Label the x and y axes with dark green text title(xlab="Days",
		col.lab=rgb(0,0.5,0)) title(ylab="Total", col.lab=rgb(0,0.5,0))
		
		# Create a legend at (1, g_range[2]) that is slightly smaller #
		(cex) and uses the same line colors and points used by # the
		actual plots legend(1, g_range[2], c("cars","trucks"), cex=0.8,
		col=c("blue","red"), pch=21:22, lty=1:2);
		
		\end{verbatim}
	\end{framed}
	\subsection{Bar charts}
	\begin{framed}
		\begin{verbatim}
		# Define the cars vector with 7 values
		cars <- c(1, 3, 6, 4, 9, 5, 7)
		# Graph cars
		barplot(cars)
		\end{verbatim}
	\end{framed}
	\subsection{Boxplots}
	\subsection{Setting graphical parameters}
	\subsection{Miscellaneous}
	The following code can be used to make variations of the plots.
	
	\begin{framed}
		\large \begin{verbatim}
		# Make an empty chart
		plot(1, 1, xlim=c(1,5.5), ylim=c(0,7), type="n", ann=FALSE)
		
		# Plot digits 0-4 with increasing size and color
		text(1:5, rep(6,5), labels=c(0:4), cex=1:5, col=1:5)
		
		# Plot symbols 0-4 with increasing size and color
		points(1:5, rep(5,5), cex=1:5, col=1:5, pch=0:4)
		text((1:5)+0.4, rep(5,5), cex=0.6, (0:4))
		
		# Plot symbols 5-9 with labels
		points(1:5, rep(4,5), cex=2, pch=(5:9))
		text((1:5)+0.4, rep(4,5), cex=0.6, (5:9))
		
		# Plot symbols 10-14 with labels
		points(1:5, rep(3,5), cex=2, pch=(10:14))
		text((1:5)+0.4, rep(3,5), cex=0.6, (10:14))
		
		# Plot symbols 15-19 with labels
		points(1:5, rep(2,5), cex=2, pch=(15:19))
		text((1:5)+0.4, rep(2,5), cex=0.6, (15:19))
		
		# Plot symbols 20-25 with labels
		points((1:6)*0.8+0.2, rep(1,6), cex=2, pch=(20:25))
		text((1:6)*0.8+0.5, rep(1,6), cex=0.6, (20:25))
		\end{verbatim}\large
	\end{framed}
	
	\subsection{Lattice Graphs}
	\subsection{setting up}
	Execute the following command:
	\begin{framed}
		\begin{verbatim}
		library(lattice)
		\end{verbatim}
	\end{framed}
	For information on lattice, type:
	\begin{framed}
		\begin{verbatim}
		help(package = lattice)
		\end{verbatim}
	\end{framed}
	The examples in this section are generally drawn from the R documentation and Murrell (2006).
	
	Murrell gives three reasons for using Lattice Graphics:
	
	They usually look better.
	They can be extended in powerful ways.
	The resulting output can be annotated, edited, and saved
	
	\subsection{3 Dimensional Graphs}
	How to do a 3-d graph
	
	\newpage
	\chapter{Statistical Analysis using R}
	\section{Confidence Intervals}
	\subsection{Confidence Intervals for Large Samples}
	\subsection{Confidence Intervals for Small Samples}
	
	\section{Linear Models}
	
	The Slope and Intercept
	\begin{framed}
		\begin{verbatim}
		
		\end{verbatim}
	\end{framed}
	
	\section{ANOVA}
	
	
	%--------------------------------------------------------Inference Procedures and testing for Normality-%
	\newpage
	%\chapter{Normality Assumptions and Outliers}
	%\subsubsection{Grubbs Test for outliers}
	%\subsection{Anderson Darling Test}
	%\subsection{Normal Probability plots}
	%\subsubsection{ Kolmogorov Smirnov Test}
	
	
	
	
	
	\subsection{Subsetting datasets by rows}
	
	Suppose we wish to divide a data frame into two different section. The simplest approach we can take is to create two new data sets, each assigned data from the relevant rows of the original data set.
	
	Suppose our dataset ``Info" has the dimensions of 200 rows and 4 columns. We wish to separate "Info" into two subsets , with the first and second 100 rows respectively. ( We call these new subsets "Info.1" and "Info.2".)
	\begin{verbatim}
	Info.1 = Info[1:100,]		#assigning "info" rows 1 to 100
	Info.2 = Info[101:200,]		#assigning "info" rows 101 to 200
	\end{verbatim}
	
	More useful commands such as rbind() and cbind()  can be used to manipulate vectors.
	
	Part 2 Strategies for Data project
	\begin{itemize}
		\item Exploratory Data Analysis
		
		The first part of your report should contain some descriptive statistics and summary values. Also include some tests for normality.
		
		\item{Regression}
		You should have a data set with multiple columns, suitable for regression analysis.
		Familiarize yourself with the data, and decide which variable is the dependent variable.
		
		Also determine the independent variables that you will use as part of your analysis.
		
		\item{Correlation Analysis}
		Compute the Pearson correlation for the dependent variable with the respective independent variables.  As part of your report, mention the confidence interval for the correlation estimate
		Choose the independent variables with the highest correlation as your candidate variables.
		For these independent variables, perform a series of simple linear regression procedures.
		\begin{verbatim}
		lm(y~x1)
		lm(y~x2)
		\end{verbatim}
		Comment on the slope and intercept estimates and their respective p-values. Also comment on the coefficient of determination (multiple R squared). Remember to write the regression equations.
		Perform a series of multiple linear regressions, using pairs of candidate independent variables.
		\begin{verbatim}
		lm(y~x1 +x2)
		lm(y~x2 +x3)
		\end{verbatim}
		Again, comment on the slope and intercept estimates, and their respective p-values.
		In this instance, compare each of the models using the coefficient of determinations. Which model explains the data best?
		\subsection{Analysis of residuals}
		Perform an analysis of regression residuals ( you can pick the best regression model from last section).
		Are the residuals normally distributed?
		Histogram /  Boxplot / QQ plot / Shapiro Wilk Test
		Also you can plot the residuals to check that there is constant variance.
		\begin{verbatim}
		y=rnorm(10)
		x=rnorm(10)
		fit1=lm(y~x)
		res.fit1 = resid(fit1)
		plot(res.fit1)
		\end{verbatim}
		
		
		
		
		%---------------------------------------------------------------------------Probability Distributions ----%
		\newpage
		\chapter{Probability Distributions}
		\section{Generating a set of random numbers}
		
		\begin{framed}
			\large \begin{verbatim}
			rnorm(10)
			\end{verbatim}\large
		\end{framed}
		
		\section{The Poisson Distribution}
		\section{The Binomial Distribution}
		\section{Using probability distributions for simulations}
		\section{Probability Distributions}
		\subsection{Generate random numbers }
		
		%----------------------------------------------------------------------------Graphical Methods--%
		\newpage
		\chapter{Graphical methods}
		
		\section{Scatterplots}
		%\begin{figure}
		% Requires \usepackage{graphicx}
		% \includegraphics[scale=0.40]{MTCARSmpgwt.png}\\
		% \caption{Scatterplot}\label{mpgwt}
		% \end{figure}
		
		
		\section{Adding titles, lines, points to plots}
		
		
		\large \begin{verbatim}
		library(MASS)
		# Colour points and choose plotting symbols according to a levels of a factor
		plot(Cars93$Weight, Cars93$EngineSize, col=as.numeric(Cars93$Type),
		pch=as.numeric(Cars93$Type))
		
		# Adds x and y axes labels and a title.
		plot(Cars93$Weight, Cars93$EngineSize, ylab="Engine Size",
		xlab="Weight", main="My plot")
		# Add lines to the plot.
		lines(x=c(min(Cars93$Weight), max(Cars93$Weight)), y=c(min(Cars93$EngineSize),
		max(Cars93$EngineSize)), lwd=4, lty=3, col="green")
		abline(h=3, lty=2)
		abline(v=1999, lty=4)
		# Add points to the plot.
		\end{verbatim}\large
		
		\newpage
		\chapter{Programming}
		
		\section{Writing Functions}
		
		A simple function can be constructed as follows:
		
		\begin{verbatim}
		function_name <- function(arg1, arg2, ...){
		commands
		output
		}
		\end{verbatim}
		
		You decide on the name of the function. The function command shows R that you are writing a function. Inside the parenthesis you outline the input objects required and decide what to call them. The commands occur inside the { }.
		
		The name of whatever output you want goes at the end of the function. Comments lines (usually a description of what the function does is placed at the beginning) are denoted by "\#".
		
		\begin{verbatim}sf1 <- function(x){
		x^2
		}
		\end{verbatim}
		
		This function is called sf1. It has one argument, called x.
		Whatever value is inputted for x will be squared and the result outputted to the screen. This function must be loaded into \texttt{R} and can then be called. We can call the function using:
		\begin{verbatim}
		sf1(x = 3)
		#sf1(3)
		[1] 9
		To store the result into a variable x.sq
		x.sq <- sf1(x = 3)
		x.sq <- sf1(3)
		> x.sq
		[1] 9
		\end{verbatim}
		Example
		\begin{verbatim}
		sf2 <- function(a1, a2, a3){
		x <- sqrt(a1^2 + a2^2 + a3^2)
		return(x)
		}
		\end{verbatim}
		
		This function is called sf2 with 3 arguments. The values inputted for a1, a2, a3 will be squared, summed and the square root of the sum calculated and stored in x. (There will be no output to the screen as in the last example.)
		The return command specifies what the function returns, here the value of x. We will not be able to view the result of the function unless we store it.
		\begin{verbatim}sf2(a1=2, a2=3, a3=4)
		sf2(2, 3, 4) # Can't see result.
		res <- sf2(a1=2, a2=3, a3=4)
		res <- sf2(2, 3, 4) # Need to use this.
		res
		[1] 5.385165
		\end{verbatim}
		We can also give some/all arguments default values.
		\begin{verbatim}mypower <- function(x, pow=2){
		x^pow
		}
		\end{verbatim}
		If a value for the argument pow is not specified in the function call,
		a value of 2 is used.
		\begin{verbatim}mypower(4)
		[1] 16
		\end{verbatim}
		If a value for "pow" is specified, that value is used.
		\begin{verbatim}
		mypower(4, 3)
		[1] 64
		mypower(pow=5, x=2)
		[1] 32
		\end{verbatim}
		
		
		
		
		
		
		
		
		%----------------------------------------------------%
		
		
		\large \begin{verbatim}
		> code here
		\end{verbatim}\large
		
		
		\large \begin{verbatim}
		> code here
		\end{verbatim}\large
		
		
		
		%---------------------------------------------------%
		\subsubsection{slide234}
		The TS are <equation here>  
		The p-values for both of these tests are 0 and so there is enough evidence to reject $H_0$ and conclude that both 0 and 1 are not 0, i.e. there is a significant linear relationship between x and y. 
		Also given are the $R^2$ and $R^2$ adjusted values. Here $R^2 = SSR/SST = 0.8813$ and so $88.13\%$ of the variation in y is being explained by x. 
		The final line gives the result of using the ANOVA table to assess the model t.
		
		%----------------------------------------------------%
		
		\subsubsection{slide235}
		
		In SLR, the ANOVA table tests <EQN>The TS is the F value and the critical value and p-values are found
		in the F tables with (p - 1) and (n - p) degrees of freedom.
		
		This output gives the p-value = 0, therefore there is enough evidence to reject H0 and conclude that there is a signicant linear relationship between y and x. The full ANOVA table can be accessed using :
		
		<TABLE HERE>
		
		
		
		\subsubsection{slide236}
		Once the model has been tted, must then check the residuals.
		The residuals should be independent and normally distributed with
		mean of 0 and constant variance.
		A Q-Q plot checks the assumption of normality (can also use a
		histogram as in MINITAB) while a, plot of the residuals versus fitted values gives an indication as to whether the assumption of constant variance holds.
		
		<HISTOGRAM>
		
		
		%----------------------------------------------------%
		\subsubsection{slidename}
		
		\large \begin{verbatim}
		> xbar <- 83
		> sigma <- 12
		> n <- 5
		> sem <- sigma/sqrt(n)
		> sem
		[1] 5.366563
		> xbar + sem * qnorm(0.025)
		[1] 72.48173
		> xbar + sem * qnorm(0.975)
		[1] 93.51827
		\end{verbatim}\large
		
		
		\subsubsection{Testing the slope (II)}
		
		You can compute a
		t test for that hypothesis simply by dividing the estimate by its standard
		error
		\begin{equation}
		t = \frac{\hat{\beta}}{S.E.(\hat{\beta})}
		\end{equation}
		which follows a t distribution on n - 2 degrees of freedom if the true $\beta$ is
		zero.
		
		
		%----------------------------------------------------%
		\begin{itemize}
			\item The standard $\chi^{2}$ test  in chisq.test works with data in matrix form, like fisher.test does.
			\item For a 2 by 2 table, the test is exactly equivalent to prop.test.
		\end{itemize}
		
		
		\large \begin{verbatim}
		> chisq.test(lewitt.machin)
		\end{verbatim}\large
		
		
		%----------------------------------------------------%
		
		\subsubsection{Chi-squared Test}
		
		A $chi^2$ test is carried out on tabular data containing counts, e.g. the
		number of animals that died, the number of days of rain, the
		number of stocks that grew in value, etc.
		
		Usually have two qualitative variables, each with a number of
		levels, and want to determine if there is a relationship between the
		two variables, e.g. hair colour and eye colour, social status and
		crime rates, house price and house size, gender and left/right
		handedness.
		
		The data are presented in a contingency table:
		right-handed left-handed TOTAL
		
		\begin{tabular}{|c|c|c|c|}
			\hline
			% after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
			& right-handed &left-handed & TOTAL\\\hline
			Male & 43 & 9 & 52 \\
			Female & 44 & 4 & 48 \\
			TOTAL & 87 & 13 & 100 \\
			\hline
		\end{tabular}
		
		
		The hypothesis to be tested is
		$H0 :$There is no relationship between gender and left/right-handedness
		$H1 :$There is a relationship between gender and left/right-handedness
		The values that we collect from our sample are called the observed
		(O) frequencies (counts). Now need to calculate the expected (E)
		frequencies, i.e. the values we would expect to see in the table, if
		H0 was true.
		
		
		
		
		
		
		%------------------------------------------------------%
		\subsubsection{Two Sample Tests}
		
		
		All of the previous hypothesis tests and confidence intervals can be
		extended to the two-sample case.
		
		The same assumptions apply, i.e. data are normally distributed in
		each population and we may want to test if the mean in one
		population is the same as the mean in the other population, etc.
		
		Normality can be checked using histograms, boxplots and Q-Q
		plots as before. The Anderson-Darling test can be used on
		each group of data also.
		
		
		%------------------------------------------------------%
		\subsubsection{Implementation}
		
		This can be carried out in R by hand:
		
		\large \begin{verbatim}
		>obs.vals <- matrix(c(43,9,44,4), nrow=2, byrow=T)
		>row.tots <- apply(obs.vals, 1, sum)
		>col.tots <- apply(obs.vals, 2, sum)
		>exp.vals <- row.tots%o%col.tots/sum(obs.vals)
		>TS <- sum((obs.vals-exp.vals)^2/exp.vals)
		>TS
		>[1] 1.777415
		\end{verbatim}\large
		
		
		%------------------------------------------------------%
		
		
		
		
		\chapter { R Graphics}
		\section Enhancing your scatter plots
		\subsection{Adding lines}
		Previously we have used scatter plots to plot bivariate data. They were constructed using the plot() command.
		Recall that we can use the arguments \texttt{xlim} and \texttt{ylim} to control the vertical and horizontal range of the plots, by specifying a two element vector (min and max) for each.
		
		Using the \texttt{abline()} command, we can add lines to our scatter plots. We specify the argument according to the type of line required. A demonstration of three types of line is provided below.
		Additionally we change the colour of the added lines, by specifying a colour in the \texttt{col} argument. We can also change the line type to one of four possible types, using the \texttt{lty} argument.
		
		The line types are follows
		\begin{itemize}
			\item	\texttt{lty =1}   Normal full line (default)
			\item	\texttt{lty =2}   Dashed line
			\item	\texttt{lty =3}   Dotted line
			\item	\texttt{lty =4}   Dash-dot line
		\end{itemize}
		\large \begin{verbatim}
		x=rnorm(10)
		y=rnorm(10)
		plot(x,y)
		plot(x,y,xlim=c(-4,4),ylim=c(-4,4))
		abline(v =0 , lty =2 )    # add a vertical dotted line (here the y-axis) to the plot
		abline(h=0  ,lty =3)    # add a horizontal dotted line (here the x-axis) to the plot
		abline(a=0,b=1,col="green") # add a line to your plot with intercept "a" and slope "b"
		\end{verbatim}\large
		
		\subsection{Changing your plot character}
		
		To change the plot character (the symbol for each covariate, we supply an additional argument to the plot() function.  This argument is formulated as pch=n where n is some number.
		Additionally we change the colour of the characters, by specifying a colour in the col argument.
		\large \begin{verbatim}
		plot(x,y,pch=15,col="red")		#Square plot symbols
		plot(x,y,pch=16,col="green")		#Orb plot symbols
		plot(x,y,pch=17,col="mauve")		#Triangular plot symbols
		plot(x,y,pch=36	,col="amber")		#Dollar sign plot symbols
		\end{verbatim}\large
		Recall that we can add new variates to an existing scatterplot using the points() function. Remember to set the vertical and horizontal limits accordingly.
		\large \begin{verbatim}
		y1 = rnorm(10); y2 = rnorm(10)
		plot(x,y1, pch=8,col="purple" ,xlim=c(-5,5),ylim=c(-5,5))
		points(x,y2,pch=12,col="green")
		\end{verbatim}\large
		\subsection{Adding the regression model line}
		
		The \texttt{abline()} function can be used to add a regression model line  by supplying as an argument the \texttt{coef()} values for intercept and slope estimates .These estimates can be inputted directly by using both functions in conjunction.
		
		\large \begin{verbatim}
		Fit1 =lm(y1~x);  coef(Fit1)
		abline(coef(Fit1))	
		\end{verbatim}\large
		
		\subsection{Adding a title }
		
		It is good practice to label your scatterplots properly. You can specify the following argument
		\begin{itemize}
			\item	main="Scatterplot Example", 	This provides the plot with a title
			\item	sub="Subtitle",                 This adds a subtitle
			\item	xlab="X variable ",				This command labels the x axis 
			\item   ylab="y variable ",				This command labels the y-axis
		\end{itemize}
		We can also add text to each margin, using the \texttt{mtext()} command.  
		We simply require the number of the side. (1 = bottom, 2=left,3=top,4=right). 
		We can change the colour using the col argument.
		\large \begin{verbatim}
		plot(x,y,main="Scatterplot Example",   sub="subtitle",    xlab="X variable ", ylab="y variable ")	
		mtext("Enhanced Scatterplot", side=4,col="red ")
		\end{verbatim}\large
		Alternatively , we can also use the command title() to add a title to an existing scatterplot.
		\large \begin{verbatim}
		title(main="Scatterplot Example)	
		\end{verbatim}\large
		
		
		\section{Combining plots}
		It is possible to combine two plots. We used the graphical parameters command \texttt{par()} to create an array. 
		Often we just require two plots side by side or above and below. We simply specify the numbers of rows and columns of this array using the \texttt{mfrow} argument, passed as a vector.
		
		\begin{verbatim}
		par(mfrow=c(1,2))
		plot(x,y1)			# draw first plot
		plot(x,y2)			# draw second plot
		par(mfrow=c(1,1))		# reset to default setting.
		\end{verbatim}
		
		\section{Plot of single vectors}
		If only one vector is specified i.e. \texttt{plot(x)},  the plot created will simply be a scatter-plot of the values of x against their indices.
		
		$plot(x)$
		Suppose we wish to examine a trend that these points represent. We can connect each covariate using a line.
		
		$plot(x, type = "l")$
		If we wish to have both lines and points, we would input the following code. This is quite useful if we wish to see how a trend develops over time.
		$plot(x, type = "b")$
		
		
		
		
		
		
		
		
		
		\section{Exercise} The following are measurements (in mm) of a critical
		dimension on a sample of twelve engine crankshafts:
		
		\begin{verbatim}
		224.120 	224.001 	224.017 	223.982 	223.989 	223.961
		223.960 	224.089 	223.987 	223.976 	223.902 	223.980
		\end{verbatim}
		(a) Calculate the mean and standard deviation for these data.
		(b) The process mean is supposed to be ? = 224mm. Is this the
		case? Give reasons for your answer.
		(c) Construct a 99\% confidence interval for these data and interpret.
		(d) Check that the normality assumption is valid using 2 suitable plots.
		
		\begin{verbatim}
		> x<-c(224.120,224.001,224.017,223.982 ,223.989 ,223.961,
		+ 223.960 ,224.089 ,223.987 ,223.976 , 223.902 ,223.980)
		>
		> mean(x)
		[1] 223.997
		>
		> sd(x)
		[1] 0.05785405
		>
		> t.test(x,mu=224,conf.level=0.99)
		
		One Sample t-test
		
		data:  x
		t = -0.1796, df = 11, p-value = 0.8607
		alternative hypothesis: true mean is not equal to 224
		99 percent confidence interval:
		223.9451 224.0489
		sample estimates:
		mean of x
		223.997
		
		\end{verbatim}
		\section{Exercise 2} 
		The height of 12 Americans and 10 Japanese was measured. Test for a difference in the heights of both populations.
		\begin{verbatim}
		Americans
		174.68   	169.87 	   	165.07    	165.95 		204.99 		177.61 	
		170.11 	 	170.71 	   	181.52 		167.68 		158.62 		182.90
		Japanese
		158.76  		168.85  		159.64  		180.02  		164.24
		161.91  		163.99  		152.71  		157.32  		147.20
		\end{verbatim}
		
		
		\section{Exercise 3}
		
		A large group of students each took two exams. The marks obtained in both exams by a sample of eight students is given below
		
		\begin{verbatim}
		Student	1	2	3	4	5	6	7	8
		Exam 1	57	76	47	39	62	56	49	81
		Exam 2	67	81	62	49	57	61	59	71
		\end{verbatim}
		Test the hypothesis that in the group as a whole the mean mark gained did not vary according to the exam against the hypothesis that the mean mark in the second exam was higher
		\begin{verbatim}
		>
		> Ex1<-c(57,76,47,39,62,56,49,81)
		> Ex2<-c(67,81,62,49,57,61,59,71)
		> t.test(Ex1-Ex2)
		
		One Sample t-test
		
		data:  Ex1 - Ex2
		t = -1.6733, df = 7, p-value = 0.1382
		alternative hypothesis: true mean is not equal to 0
		95 percent confidence interval:
		-12.065666   2.065666
		sample estimates:
		mean of x
		-5
		\end{verbatim}
		
		\section{Exercise 4}
		A poll on social issues interviewed 1025 people randomly selected from the United States. 450 of people said that they do not get enough time to themselves. A report claims that over 41\% of the population are not satisfied with personal time. Is this the case?
		
		\begin{verbatim}
		
		> prop.test(450,1025,p=0.40,alternative="greater")
		
		1-sample proportions test with continuity correction
		
		data:  450 out of 1025, null probability 0.4
		X-squared = 6.3425, df = 1, p-value = 0.005894
		alternative hypothesis: true p is greater than 0.4
		95 percent confidence interval:
		0.413238 1.000000
		sample estimates:
		p
		0.4390244
		\end{verbatim}
		
		Exercise 23b:  A company wants to investigate the proportion of males and females promoted in the last year. 45 out of 400 female candidates were promoted, while 520 out of 3270 male candidates were promoted. Is there evidence of sexism in the company?
		\begin{verbatim}
		> x.vec=c(45,520)
		> n.vec=c(400,3270)
		>  prop.test(x.vec,n.vec)
		
		2-sample test for equality of proportions with continuity correction
		
		data:  x.vec out of n.vec
		X-squared = 5.5702, df = 1, p-value = 0.01827
		alternative hypothesis: two.sided
		95 percent confidence interval:
		-0.08133043 -0.01171238
		sample estimates:
		prop 1    prop 2
		0.1125000 0.1590214
		\end{verbatim}
		
		?
		\section{Exercise}
		
		Generate a histogram for data set 'scores', with an accompanying box-and-whisker plot.
		The colour of the histogram's bar should be yellow. The orientation for the boxplot should be horizontal.
		
		\begin{verbatim}
		scores <-c(23,19,22,22,19,20,25,26,26,19,24,23,17,21,28,26)
		
		par(mfrow=c(2,1)) 	# two rows , one column
		
		hist(scores,main="Distribution of scores",xlab="scores",col="yellow")
		
		boxplot(scores ,horizontal=TRUE)
		
		par(mfrow =c(1,1)) 	#reset
		\end{verbatim}
		\section{The R Programming Language}
		
		The R Programming Language is a statistical , data analysis , etc
		
		R is a free software environment for statistical computing and graphics.
		
		\section{Writing R scripts}
		Editing your R script ``R Editor".
		\begin{itemize}
			\item On the menu of the R console, click on file.
			\item Select open script or new script as appropriate.
			\item Navigate to your working directory and select your \texttt{.R} file
			\item A new dialogue box ``\texttt{the R editor}" will open up.
			\item Input or select code you wish to compile.
			\item To compile this code, highlight it. Click the edit button on the menu.
			\item Select either ``Run Line" or ``Run Selection or All".
			\item Your code should now compile.
			\item To save your code, clink on ``file" and then ``\texttt{save as}".
			\item Save the file with the ``\texttt{.R}" extension to your working directory.
		\end{itemize}
		
		\section{Vector types}
		\texttt{R} operates on named data structures. The simplest such structure is the
		vector, which is a single entity consisting of an ordered collection of
		Numbers or characters.
		
		\begin{itemize}
			\item Numeric vectors
			\item Character vectors
			\item Logical vectors
			\item (also complex number vectors and colour vectors)
		\end{itemize}
		
		To create a vector, use the assignment operator and the concatenate function.
		For numeric vectors, the values are simply numbers.
		
		\begin{verbatim}
		># week8.r
		>NumVec<-c(10.4,5.6,3.1,6.4)
		\end{verbatim}
		
		Alternatively we can use the \texttt{assign()} command
		
		For character vectors, the values are simply characters, specified with
		quotation marks.A logical vectors is a vector whose elements are TRUE, FALSE or NA
		
		\begin{verbatim}
		>CharVec<-c(``blue", ``green", ``yellow")
		>LogVec<-c(TRUE, FALSE)
		\end{verbatim}
		
		\section{Graphical data entry interface}
		
		\texttt{Data.entry()} is a useful  command for inputting or editing data sets. Any
		changes are saved automatically (i.e. dont need to use the assignment
		operator). We can also used the \texttt{edit()} command, which calls the \texttt{R Editor}.
		
		\begin{verbatim}
		>data.entry(NumVec)
		>NumVec <- edit(NumVec)
		\end{verbatim}
		
		Another method of creating vectors is to use the following
		\begin{verbatim}
		numeric (length = n)
		character (length = n)
		logical (length = n)
		\end{verbatim}
		These commands create empty vectors, of the appropriate kind, of length $n$. You can then use the graphical data entry interface to populate your data sets.
		
		\subsubsection{Accessing specified elements of a vector}
		
		The $n$th element of vector ``Vec" can be accessed by specifying its index when
		calling ``Vec".
		\begin{verbatim}>Vec[n]
		\end{verbatim}
		A sequence of  elements of vector ``Vec" can be accessed by specifying its index
		when calling ``Vec".
		\begin{verbatim}>Vec[l:u]
		\end{verbatim}
		Omitting and deleting the $n$th element of vector ``Vec"
		\begin{verbatim}
		>Vec[-n]
		>Vec <- Vec[-n]
		\end{verbatim}
		
		\section{Reading data}
		
		
		\subsection{inputting data}
		Concatenation
		
		\subsection{using help}
		
		?mean
		
		\subsection{Adding comments}
		
		\subsection{Packages}
		The capabilities of R are extended through user-submitted packages, which allow specialized statistical techniques, graphical devices, as well as and
		import/export capabilities to many external data formats.
		
		\section{Managing Precision}
		\begin{itemize}
			\item \texttt{floor()} - 
			\item \texttt{ceiling()} - 
			\item \texttt{round()} - 
			\item \texttt{as.integer()} -
		\end{itemize}
		
		\begin{framed}
			\begin{verbatim}
			> pi
			[1] 3.141593
			> floor(pi)
			[1] 3
			> ceiling(pi)
			[1] 4
			> round(pi,3)
			[1] 3.142
			> as.integer(pi)
			[1] 3
			\end{verbatim}
		\end{framed}
		
		\section{Basic Operations}
		\subsection{Complex numbers}
		\subsection{Trigonometric functions}
		\section{Matrices}
		
		%\end{document}
		
		
		\subsubsection{exponentials, powers and logarithms}
		\begin{framed}
			\begin{verbatim}
			>x^y
			>exp(x)
			>log(x)
			>log(y)
			#determining the square root of x
			>sqrt(x)
			\end{verbatim}
		\end{framed}
		
		\subsection{vectors}
		\begin{framed}
			\begin{verbatim}
			R handles vector objects quite easily and intuitively.
			
			> x<-c(1,3,2,10,5)    #create a vector x with 5 components
			> x
			[1]  1  3  2 10  5
			> y<-1:5              #create a vector of consecutive integers
			> y
			[1] 1 2 3 4 5
			> y+2                 #scalar addition
			[1] 3 4 5 6 7
			> 2*y                 #scalar multiplication
			[1]  2  4  6  8 10
			> y^2                 #raise each component to the second power
			[1]  1  4  9 16 25
			> 2^y                 #raise 2 to the first through fifth power
			[1]  2  4  8 16 32
			> y                   #y itself has not been unchanged
			[1] 1 2 3 4 5
			> y<-y*2
			> y                   #it is now changed
			[1]  2  4  6  8 10
			\end{verbatim}
		\end{framed}
		
		\subsubsection{Misc}
		\texttt{seq()} and \texttt{rep()} are useful commands for constructing vectors with a certain pattern.
		
		%\end{document}
		
		\subsection{Matrices}
		A matrix refers to a numeric array of rows and columns.
		
		One of the easiest ways to create a matrix is to combine vectors of equal
		length using cbind(), meaning "column bind". Alternatively one can use rbind(), meaning ``row bind".
		
		
		\subsubsection{Matrices Inversion}
		\subsubsection{Matrices Multiplication}
		
		
		\subsection{Data frame}
		A Data frame is
		\newpage
		
		%------------------------------------------------------------------------------------------------%
		
		\chapter{Descriptive Statistics}
		
		\section{Basic Statistics}
		
		\large
		\begin{framed}
			\begin{verbatim}
			> X=c(1,4,5,7,8,9,5,8,9)
			> mean(X);median(X)       #mean and median of vector
			[1] 6.222222
			[2] 7
			> sd(X)                   #standard deviation of Vector
			[1] 2.682246
			> length(X)               #sample size of vector
			[1] 9
			> sum(X)
			[1] 56
			> X^2
			[1]  1 16 25 49 64 81 25 64 81
			> rev(X)
			[1] 9 8 5 9 8 7 5 4 1
			> sort(X)                 #items in ascending order
			[1] 1 4 5 5 7 8 8 9 9
			> X[1:5]
			[1] 1 4 5 7 8
			\end{verbatim}
		\end{framed}
		\large
		
		
		\section{Summary Statistics}
		The \texttt{R} command \texttt{summary()} returns a summary statistics for a simple dataset.
		The \texttt{R} command \texttt{fivenum()} returns a summary statistics for a simple dataset, but without the mean.
		Also, the quartiles are computed a different way.
		
		\large
		\begin{framed}
			\begin{verbatim}
			> summary(mtcars$mpg)
			Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
			10.40   15.43   19.20   20.09   22.80   33.90 
			>
			> fivenum(mtcars$mpg)
			[1] 10.40 15.35 19.20 22.80 33.90
			\end{verbatim}
		\end{framed}
		\large
		
		
		
		
		\section{Bivariate Data}
		\large \begin{framed}
			\begin{verbatim}
			> Y=mtcars$mpg
			> X=mtcars$wt
			>
			> cor(X,Y)          #Correlation
			[1] -0.8676594
			>
			> cov(X,Y)          #Covariance
			[1] -5.116685
			\end{verbatim}
		\end{framed}\large
		
		
		\section{Histograms}
		Histograms can be created using the \texttt{hist()} command.
		To create a histogram of the car weights from the Cars93 data set
		\large
		\begin{framed}
			\begin{verbatim}
			hist(mtcars$mpg, main="Histogram of MPG (Data: MTCARS) ")
			\end{verbatim}
		\end{framed}\large
		\texttt{R} automatically chooses the number and width of the bars. We can
		change this by specifying the location of the break points.
		\large
		
		\begin{verbatim}hist(Cars93$Weight, breaks=c(1500, 2050, 2300, 2350, 2400,
		2500, 3000, 3500, 3570, 4000, 4500), xlab="Weight",
		main="Histogram of Weight")
		\end{verbatim}
		
		
	
	\section{Boxplot}
	Boxplots can be used to identify outliers.
	
	By default, the \texttt{boxplot()} command sets the orientation as vertical. By adding the argument \texttt{horizontal=TRUE}, the orientation can be changed to horizontal.
	\large
	\begin{framed}
		\begin{verbatim}
		boxplot(mtcars$mpg, horizontal=TRUE, xlab="Miles Per Gallon",
		main="Boxplot of MPG")
		\end{verbatim}
	\end{framed}
	
	%\begin{figure}
	%  Requires \usepackage{graphicx}
	%  \includegraphics[scale=0.4]{MTCARSboxplot.png}\\
	%  \caption{Boxplot}\label{boxplot}
	%\end{figure}
	
	
	
	\newpage
	\chapter{Advanced R code}
	\section{Data frame}
	A Data frame is
	\subsection{Merging Data frames}
	
	\section{Functions}
	Syntax to define functions
	
	\begin{framed}
		\begin{verbatim}
		myfct <- function(arg1, arg2, ...) { function_body }
		\end{verbatim}
	\end{framed}
	The value returned by a function is the value of the function body, which is usually an unassigned final expression, e.g.: return()
	
	Syntax to call functions
	\begin{framed}
		\begin{verbatim}
		myfct(arg1=..., arg2=...)
		\end{verbatim}
	\end{framed}
	
	
	\subsection{Time and Date}
	It is useful . The length of time a program takes is interesting.
	
	
	\begin{framed}
		\begin{verbatim}
		date() # returns the current system date and time
		\end{verbatim}
	\end{framed}
	
	
	\section{The Apply family}
	
	Sometimes want to apply a function to each element of a
	vector/data frame/list/array.
	\\
	Four members: lapply, sapply, tapply, apply
	\\
	lapply: takes any structure and gives a list of results (hence
	the `l')
	\\
	sapply: like lapply, but tries to simplify the result to a
	vector or matrix if possible (hence the `s')
	\\
	apply: only used for arrays/matrices
	\\
	tapply: allows you to create tables (hence the `t') of values
	from subgroups defined by one or more factors.
	\newpage
	
	\section{Plots}
	This section is an introduction for producing simple graphs with
	the R Programming Language.
	\begin{itemize}
		\item Line Charts  \item Bar Charts \item Histograms \item Pie
		Charts \item Dotcharts
	\end{itemize}
	
	
	\begin{itemize}
		\item
		\item
	\end{itemize}
	\large \begin{verbatim}
	> code here
	\end{verbatim}\large
	
	
	\subsection{ Charts}
	
	\begin{framed}
		\begin{verbatim}
		# Define 2 vectors cars <- c(1, 3, 6, 4, 9) trucks <- c(2, 5, 4,
		5, 12)
		
		# Calculate range from 0 to max value of cars and trucks g_range
		<- range(0, cars, trucks)
		
		# Graph autos using y axis that ranges from 0 to max # value in
		cars or trucks vector.  Turn off axes and # annotations (axis
		labels) so we can specify them ourself plot(cars, type="o",
		col="blue", ylim=g_range,
		axes=FALSE, ann=FALSE)
		
		# Make x axis using Mon-Fri labels axis(1, at=1:5,
		lab=c("Mon","Tue","Wed","Thu","Fri"))
		
		# Make y axis with horizontal labels that display ticks at # every
		4 marks. 4*0:g_range[2] is equivalent to c(0,4,8,12). axis(2,
		las=1, at=4*0:g_range[2])
		
		# Create box around plot box()
		
		# Graph trucks with red dashed line and square points
		lines(trucks, type="o", pch=22, lty=2, col="red")
		
		# Create a title with a red, bold/italic font title(main="Autos",
		col.main="red", font.main=4)
		
		# Label the x and y axes with dark green text title(xlab="Days",
		col.lab=rgb(0,0.5,0)) title(ylab="Total", col.lab=rgb(0,0.5,0))
		
		# Create a legend at (1, g_range[2]) that is slightly smaller #
		(cex) and uses the same line colors and points used by # the
		actual plots legend(1, g_range[2], c("cars","trucks"), cex=0.8,
		col=c("blue","red"), pch=21:22, lty=1:2);
		
		\end{verbatim}
	\end{framed}
	\subsection{Bar charts}
	\begin{framed}
		\begin{verbatim}
		# Define the cars vector with 7 values
		cars <- c(1, 3, 6, 4, 9, 5, 7)
		# Graph cars
		barplot(cars)
		\end{verbatim}
	\end{framed}
	\subsection{Boxplots}
	\subsection{Setting graphical parameters}
	\subsection{Miscellaneous}
	The following code can be used to make variations of the plots.
	
	\begin{framed}
		\large \begin{verbatim}
		# Make an empty chart
		plot(1, 1, xlim=c(1,5.5), ylim=c(0,7), type="n", ann=FALSE)
		
		# Plot digits 0-4 with increasing size and color
		text(1:5, rep(6,5), labels=c(0:4), cex=1:5, col=1:5)
		
		# Plot symbols 0-4 with increasing size and color
		points(1:5, rep(5,5), cex=1:5, col=1:5, pch=0:4)
		text((1:5)+0.4, rep(5,5), cex=0.6, (0:4))
		
		# Plot symbols 5-9 with labels
		points(1:5, rep(4,5), cex=2, pch=(5:9))
		text((1:5)+0.4, rep(4,5), cex=0.6, (5:9))
		
		# Plot symbols 10-14 with labels
		points(1:5, rep(3,5), cex=2, pch=(10:14))
		text((1:5)+0.4, rep(3,5), cex=0.6, (10:14))
		
		# Plot symbols 15-19 with labels
		points(1:5, rep(2,5), cex=2, pch=(15:19))
		text((1:5)+0.4, rep(2,5), cex=0.6, (15:19))
		
		# Plot symbols 20-25 with labels
		points((1:6)*0.8+0.2, rep(1,6), cex=2, pch=(20:25))
		text((1:6)*0.8+0.5, rep(1,6), cex=0.6, (20:25))
		\end{verbatim}\large
	\end{framed}
	
	\subsection{Lattice Graphs}
	\subsection{setting up}
	Execute the following command:
	\begin{framed}
		\begin{verbatim}
		library(lattice)
		\end{verbatim}
	\end{framed}
	For information on lattice, type:
	\begin{framed}
		\begin{verbatim}
		help(package = lattice)
		\end{verbatim}
	\end{framed}
	The examples in this section are generally drawn from the R documentation and Murrell (2006).
	
	Murrell gives three reasons for using Lattice Graphics:
	
	They usually look better.
	They can be extended in powerful ways.
	The resulting output can be annotated, edited, and saved
	
	\subsection{3 Dimensional Graphs}
	How to do a 3-d graph
	
	\newpage
	\chapter{Statistical Analysis using R}
	\section{Confidence Intervals}
	\subsection{Confidence Intervals for Large Samples}
	\subsection{Confidence Intervals for Small Samples}
	
	\section{Linear Models}
	
	The Slope and Intercept
	\begin{framed}
		\begin{verbatim}
		
		\end{verbatim}
	\end{framed}
	
	\section{ANOVA}
	
	
	%--------------------------------------------------------Inference Procedures and testing for Normality-%
	\newpage
	\chapter{Normality Assumptions and Outliers}
	\subsubsection{Grubbs Test for outliers}
	\subsection{Anderson Darling Test}
	\subsection{Normal Probability plots}
	\subsubsection{ Kolmogorov Smirnov Test}
	
	
	
	
	
	
	\subsection{Subsetting datasets by rows}
	
	Suppose we wish to divide a data frame into two different section. The simplest approach we can take is to create two new data sets, each assigned data from the relevant rows of the original data set.
	
	Suppose our dataset ``Info" has the dimensions of 200 rows and 4 columns. We wish to separate "Info" into two subsets , with the first and second 100 rows respectively. ( We call these new subsets "Info.1" and "Info.2".)
	\begin{verbatim}
	Info.1 = Info[1:100,]		#assigning "info" rows 1 to 100
	Info.2 = Info[101:200,]		#assigning "info" rows 101 to 200
	\end{verbatim}
	
	More useful commands such as rbind() and cbind()  can be used to manipulate vectors.
	
	Part 2 Strategies for Data project
	\begin{itemize}
		\item Exploratory Data Analysis
		
		The first part of your report should contain some descriptive statistics and summary values. Also include some tests for normality.
		
		\item{Regression}
		You should have a data set with multiple columns, suitable for regression analysis.
		Familiarize yourself with the data, and decide which variable is the dependent variable.
		
		Also determine the independent variables that you will use as part of your analysis.
		
		\item{Correlation Analysis}
		Compute the Pearson correlation for the dependent variable with the respective independent variables.  As part of your report, mention the confidence interval for the correlation estimate
		Choose the independent variables with the highest correlation as your candidate variables.
		For these independent variables, perform a series of simple linear regression procedures.
		\begin{verbatim}
		lm(y~x1)
		lm(y~x2)
		\end{verbatim}
		Comment on the slope and intercept estimates and their respective p-values. Also comment on the coefficient of determination (multiple R squared). Remember to write the regression equations.
		Perform a series of multiple linear regressions, using pairs of candidate independent variables.
		\begin{verbatim}
		lm(y~x1 +x2)
		lm(y~x2 +x3)
		\end{verbatim}
		Again, comment on the slope and intercept estimates, and their respective p-values.
		In this instance, compare each of the models using the coefficient of determinations. Which model explains the data best?
		\subsection{Analysis of residuals}
		Perform an analysis of regression residuals ( you can pick the best regression model from last section).
		Are the residuals normally distributed?
		Histogram /  Boxplot / QQ plot / Shapiro Wilk Test
		Also you can plot the residuals to check that there is constant variance.
		\begin{verbatim}
		y=rnorm(10)
		x=rnorm(10)
		fit1=lm(y~x)
		res.fit1 = resid(fit1)
		plot(res.fit1)
		\end{verbatim}
		
		
		
		
		%---------------------------------------------------------------------------Probability Distributions ----%
		\newpage
		\chapter{Probability Distributions}
		\section{Generating a set of random numbers}
		
		%\begin{framed}
		\large \begin{verbatim}
		rnorm(10)
		\end{verbatim}\large
		%\end{framed}
		
		\section{The Poisson Distribution}
		\section{The Binomial Distribution}
		\section{Using probability distributions for simulations}
		\section{Probability Distributions}
		\subsection{Generate random numbers }
		
		%----------------------------------------------------------------------------Graphical Methods--%
		\newpage
		\chapter{Graphical methods}
		
		\section{Scatterplots}
		%\begin{figure}
		%  % Requires \usepackage{graphicx}
		%  \includegraphics[scale=0.40]{MTCARSmpgwt.png}\\
		%  \caption{Scatterplot}\label{mpgwt}
		%\end{figure}
		
		
		\section{Adding titles, lines, points to plots}
		
		
		\large \begin{verbatim}
		library(MASS)
		# Colour points and choose plotting symbols according to a levels of a factor
		plot(Cars93$Weight, Cars93$EngineSize, col=as.numeric(Cars93$Type),
		pch=as.numeric(Cars93$Type))
		
		# Adds x and y axes labels and a title.
		plot(Cars93$Weight, Cars93$EngineSize, ylab="Engine Size",
		xlab="Weight", main="My plot")
		# Add lines to the plot.
		lines(x=c(min(Cars93$Weight), max(Cars93$Weight)), y=c(min(Cars93$EngineSize),
		max(Cars93$EngineSize)), lwd=4, lty=3, col="green")
		abline(h=3, lty=2)
		abline(v=1999, lty=4)
		# Add points to the plot.
		\end{verbatim}\large
		
		\newpage
		\chapter{Programming}
		
		
		
		
		
		
		
		%----------------------------------------------------%
		\subsubsection{Two Sample t test}
		
		The two-sample t test is used to test the hypothesis that two samples may
		be assumed to come from distributions with the same mean.
		
		The theory for the two-sample t test is not very different in principle from
		that of the one-sample test. Data are now from two groups, $x_{11}, . . . , x_{1n1}$
		and $x_{21}, . . . , x_{2n2}$ , which we assume are sampled from the normal distributions
		$N(µ_{1}, \sigma^{1}_{2} )$ and
		$N(µ_{2}, \sigma^{2}_{2} )$, and it is desired to test the null hypothesis
		$\mu_{1} = \mu_{2}$. You then calculate
		
		\[
		t = \frac{\bar{X}_{1}-\bar{X}_{2}}{S.E.(\bar{X}_{1}-\bar{X}_{2})}
		\]
		
		
		
		
		%---------------------------------------------------%
		\subsubsection{slide234}
		The TS are <equation here>  
		The p-values for both of these tests are 0 and so there is enough evidence to reject $H_0$ and conclude that both 0 and 1 are not 0, i.e. there is a significant linear relationship between x and y. 
		Also given are the $R^2$ and $R^2$ adjusted values. Here $R^2 = SSR/SST = 0.8813$ and so $88.13\%$ of the variation in y is being explained by x. 
		The final line gives the result of using the ANOVA table to assess the model t.
		
		%----------------------------------------------------%
		
		\subsubsection{slide235}
		
		In SLR, the ANOVA table tests <EQN>The TS is the F value and the critical value and p-values are found
		in the F tables with (p - 1) and (n - p) degrees of freedom.
		
		This output gives the p-value = 0, therefore there is enough evidence to reject H0 and conclude that there is a signicant linear relationship between y and x. The full ANOVA table can be accessed using :
		
		<TABLE HERE>
		
		
		
		\subsubsection{slide236}
		Once the model has been tted, must then check the residuals.
		The residuals should be independent and normally distributed with
		mean of 0 and constant variance.
		A Q-Q plot checks the assumption of normality (can also use a
		histogram as in MINITAB) while a, plot of the residuals versus fitted values gives an indication as to whether the assumption of constant variance holds.
		
		<HISTOGRAM>
		
		
		
		
		\section{Introduction to \texttt{R}}
		\texttt{R} consists of a base package and many additional packages
		\texttt{R} was originally designed as a command language.  
		Commands were typed into a text-based input area on the computer screen and the program responded with a response to each command.
		The \texttt{R} console opens with information and then a prompt mark  ``>"  it is ready to accept commands
		\texttt{R}  is an open source software package, meaning that the code written to implement the various functions can be freely examined and modified.
		\texttt{R} can be installed free of charge from the \texttt{R}-project website.
		
		%----------------------------------------------------%
		\subsubsection{slidename}
		
		\large \begin{verbatim}
		> xbar <- 83
		> sigma <- 12
		> n <- 5
		> sem <- sigma/sqrt(n)
		> sem
		[1] 5.366563
		> xbar + sem * qnorm(0.025)
		[1] 72.48173
		> xbar + sem * qnorm(0.975)
		[1] 93.51827
		\end{verbatim}\large
		
		
		\subsubsection{Testing the slope (II)}
		
		You can compute a
		t test for that hypothesis simply by dividing the estimate by its standard
		error
		\begin{equation}
		t = \frac{\hat{\beta}}{S.E.(\hat{\beta})}
		\end{equation}
		which follows a t distribution on n - 2 degrees of freedom if the true $\beta$ is
		zero.
		
		
		%----------------------------------------------------%
		\begin{itemize}
			\item The standard $\chi^{2}$ test  in chisq.test works with data in matrix form, like fisher.test does.
			\item For a 2 by 2 table, the test is exactly equivalent to prop.test.
		\end{itemize}
		
		
		\large \begin{verbatim}
		> chisq.test(lewitt.machin)
		\end{verbatim}\large
		
		
		
		
		
		
		
		\chapter { R Graphics}
		\section Enhancing your scatter plots
		\subsection{Adding lines}
		Previously we have used scatter plots to plot bivariate data. They were constructed using the plot() command.
		Recall that we can use the arguments \texttt{xlim} and \texttt{ylim} to control the vertical and horizontal range of the plots, by specifying a two element vector (min and max) for each.
		
		Using the \texttt{abline()} command, we can add lines to our scatter plots. We specify the argument according to the type of line required. A demonstration of three types of line is provided below.
		Additionally we change the colour of the added lines, by specifying a colour in the \texttt{col} argument. We can also change the line type to one of four possible types, using the \texttt{lty} argument.
		
		The line types are follows
		\begin{itemize}
			\item	\texttt{lty =1}   Normal full line (default)
			\item	\texttt{lty =2}   Dashed line
			\item	\texttt{lty =3}   Dotted line
			\item	\texttt{lty =4}   Dash-dot line
		\end{itemize}
		\large \begin{verbatim}
		x=rnorm(10)
		y=rnorm(10)
		plot(x,y)
		plot(x,y,xlim=c(-4,4),ylim=c(-4,4))
		abline(v =0 , lty =2 )    # add a vertical dotted line (here the y-axis) to the plot
		abline(h=0  ,lty =3)    # add a horizontal dotted line (here the x-axis) to the plot
		abline(a=0,b=1,col="green") # add a line to your plot with intercept "a" and slope "b"
		\end{verbatim}\large
		
		\subsection{Changing your plot character}
		
		To change the plot character (the symbol for each covariate, we supply an additional argument to the plot() function.  This argument is formulated as pch=n where n is some number.
		Additionally we change the colour of the characters, by specifying a colour in the col argument.
		\large \begin{verbatim}
		plot(x,y,pch=15,col="red")		#Square plot symbols
		plot(x,y,pch=16,col="green")		#Orb plot symbols
		plot(x,y,pch=17,col="mauve")		#Triangular plot symbols
		plot(x,y,pch=36	,col="amber")		#Dollar sign plot symbols
		\end{verbatim}\large
		Recall that we can add new variates to an existing scatterplot using the points() function. Remember to set the vertical and horizontal limits accordingly.
		\large \begin{verbatim}
		y1 = rnorm(10); y2 = rnorm(10)
		plot(x,y1, pch=8,col="purple" ,xlim=c(-5,5),ylim=c(-5,5))
		points(x,y2,pch=12,col="green")
		\end{verbatim}\large
		\subsection{Adding the regression model line}
		
		The \texttt{abline()} function can be used to add a regression model line  by supplying as an argument the \texttt{coef()} values for intercept and slope estimates .These estimates can be inputted directly by using both functions in conjunction.
		
		\large \begin{verbatim}
		Fit1 =lm(y1~x);  coef(Fit1)
		abline(coef(Fit1))	
		\end{verbatim}\large
		
		\subsection{Adding a title }
		
		It is good practice to label your scatterplots properly. You can specify the following argument
		\begin{itemize}
			\item	main="Scatterplot Example", 	This provides the plot with a title
			\item	sub="Subtitle",                 This adds a subtitle
			\item	xlab="X variable ",				This command labels the x axis 
			\item   ylab="y variable ",				This command labels the y-axis
		\end{itemize}
		We can also add text to each margin, using the \texttt{mtext()} command.  
		We simply require the number of the side. (1 = bottom, 2=left,3=top,4=right). 
		We can change the colour using the col argument.
		\large \begin{verbatim}
		plot(x,y,main="Scatterplot Example",   sub="subtitle",    xlab="X variable ", ylab="y variable ")	
		mtext("Enhanced Scatterplot", side=4,col="red ")
		\end{verbatim}\large
		Alternatively , we can also use the command title() to add a title to an existing scatterplot.
		\large \begin{verbatim}
		title(main="Scatterplot Example)	
		\end{verbatim}\large
		
		
		\section{Combining plots}
		It is possible to combine two plots. We used the graphical parameters command \texttt{par()} to create an array. 
		Often we just require two plots side by side or above and below. We simply specify the numbers of rows and columns of this array using the \texttt{mfrow} argument, passed as a vector.
		
		\begin{verbatim}
		par(mfrow=c(1,2))
		plot(x,y1)			# draw first plot
		plot(x,y2)			# draw second plot
		par(mfrow=c(1,1))		# reset to default setting.
		\end{verbatim}
		
		\section{Plot of single vectors}
		If only one vector is specified i.e. \texttt{plot(x)},  the plot created will simply be a scatter-plot of the values of x against their indices.
		
		$plot(x)$
		Suppose we wish to examine a trend that these points represent. We can connect each covariate using a line.
		
		$plot(x, type = "l")$
		If we wish to have both lines and points, we would input the following code. This is quite useful if we wish to see how a trend develops over time.
		$plot(x, type = "b")$
		
		
		
		
		
		
		
		
		
		\section{Exercise} The following are measurements (in mm) of a critical
		dimension on a sample of twelve engine crankshafts:
		
		\begin{verbatim}
		224.120 	224.001 	224.017 	223.982 	223.989 	223.961
		223.960 	224.089 	223.987 	223.976 	223.902 	223.980
		\end{verbatim}
		(a) Calculate the mean and standard deviation for these data.
		(b) The process mean is supposed to be ? = 224mm. Is this the
		case? Give reasons for your answer.
		(c) Construct a 99\% confidence interval for these data and interpret.
		(d) Check that the normality assumption is valid using 2 suitable plots.
		
		\begin{verbatim}
		> x<-c(224.120,224.001,224.017,223.982 ,223.989 ,223.961,
		+ 223.960 ,224.089 ,223.987 ,223.976 , 223.902 ,223.980)
		>
		> mean(x)
		[1] 223.997
		>
		> sd(x)
		[1] 0.05785405
		>
		> t.test(x,mu=224,conf.level=0.99)
		
		One Sample t-test
		
		data:  x
		t = -0.1796, df = 11, p-value = 0.8607
		alternative hypothesis: true mean is not equal to 224
		99 percent confidence interval:
		223.9451 224.0489
		sample estimates:
		mean of x
		223.997
		
		\end{verbatim}
		\section{Exercise 2} 
		The height of 12 Americans and 10 Japanese was measured. Test for a difference in the heights of both populations.
		\begin{verbatim}
		Americans
		174.68   	169.87 	   	165.07    	165.95 		204.99 		177.61 	
		170.11 	 	170.71 	   	181.52 		167.68 		158.62 		182.90
		Japanese
		158.76  		168.85  		159.64  		180.02  		164.24
		161.91  		163.99  		152.71  		157.32  		147.20
		\end{verbatim}
		\begin{verbatim}
		> t.test(A,J)
		Welch Two Sample t-test
		data:  A and J
		t = 2.8398, df = 19.815, p-value = 0.01018
		alternative hypothesis: true difference in means is not equal to 0
		95 percent confidence interval:
		3.360121 21.996879
		sample estimates:
		mean of x mean of y
		174.1425  161.4640
		\end{verbatim}
		
		\section{Exercise 3}
		
		A large group of students each took two exams. The marks obtained in both exams by a sample of eight students is given below
		
		\begin{verbatim}
		Student	1	2	3	4	5	6	7	8
		Exam 1	57	76	47	39	62	56	49	81
		Exam 2	67	81	62	49	57	61	59	71
		\end{verbatim}
		Test the hypothesis that in the group as a whole the mean mark gained did not vary according to the exam against the hypothesis that the mean mark in the second exam was higher
		\begin{verbatim}
		>
		> Ex1<-c(57,76,47,39,62,56,49,81)
		> Ex2<-c(67,81,62,49,57,61,59,71)
		> t.test(Ex1-Ex2)
		
		One Sample t-test
		
		data:  Ex1 - Ex2
		t = -1.6733, df = 7, p-value = 0.1382
		alternative hypothesis: true mean is not equal to 0
		95 percent confidence interval:
		-12.065666   2.065666
		sample estimates:
		mean of x
		-5
		\end{verbatim}
		
		\section{Exercise 4}
		A poll on social issues interviewed 1025 people randomly selected from the United States. 450 of people said that they do not get enough time to themselves. A report claims that over 41\% of the population are not satisfied with personal time. Is this the case?
		
		\begin{verbatim}
		
		> prop.test(450,1025,p=0.40,alternative="greater")
		
		1-sample proportions test with continuity correction
		
		data:  450 out of 1025, null probability 0.4
		X-squared = 6.3425, df = 1, p-value = 0.005894
		alternative hypothesis: true p is greater than 0.4
		95 percent confidence interval:
		0.413238 1.000000
		sample estimates:
		p
		0.4390244
		\end{verbatim}
		
		Exercise 23b:  A company wants to investigate the proportion of males and females promoted in the last year. 45 out of 400 female candidates were promoted, while 520 out of 3270 male candidates were promoted. Is there evidence of sexism in the company?
		\begin{verbatim}
		> x.vec=c(45,520)
		> n.vec=c(400,3270)
		>  prop.test(x.vec,n.vec)
		
		2-sample test for equality of proportions with continuity correction
		
		data:  x.vec out of n.vec
		X-squared = 5.5702, df = 1, p-value = 0.01827
		alternative hypothesis: two.sided
		95 percent confidence interval:
		-0.08133043 -0.01171238
		sample estimates:
		prop 1    prop 2
		0.1125000 0.1590214
		\end{verbatim}
		
		?
		\section{Exercise}
		
		Generate a histogram for data set 'scores', with an accompanying box-and-whisker plot.
		The colour of the histogram's bar should be yellow. The orientation for the boxplot should be horizontal.
		
		\begin{verbatim}
		scores <-c(23,19,22,22,19,20,25,26,26,19,24,23,17,21,28,26)
		
		par(mfrow=c(2,1)) 	# two rows , one column
		
		hist(scores,main="Distribution of scores",xlab="scores",col="yellow")
		
		boxplot(scores ,horizontal=TRUE)
		
		par(mfrow =c(1,1)) 	#reset
		\end{verbatim}
		
		%----------------------------------------------------------------%
		\section{Vector Operations}
		\begin{itemize}
			\item $R$ operates on named data structures. The simplest such
			structure is the vector, which is a single entity consisting of an
			ordered collection of numbers or characters.
			
			\item The most common types of vectors are:
			\begin{itemize}
				\item Numeric vectors \item Character vectors \item Logical
				vectors
			\end{itemize}
			
			\item There are, of course, other types of vectors.
			\begin{itemize}
				\item Colour vectors - potentially useful later on.
				\item Order vectors - The rankings of items in a vector.
				\item Complex number vectors - not part of this course.
			\end{itemize}
		\end{itemize}
		\subsection{Ordering Vector Operations}
		\begin{framed}
			\begin{verbatim}
			sort(x)  # sort x into ascending order
			rev(x)
			rev(sort(x))
			\end{verbatim}
		\end{framed}
		
		\begin{framed}
			\begin{verbatim}
			x=c(15, 34, 7, 12, 18, 9, 1, 42, 56, 28, 13, 24, 35)
			
			length(x)         # How many items in x
			median(x)         # median of data set x
			sort(x)[7]        # 7th item when x is in ascending order
			quantile(x,0.75)  # Compute the third quartile
			quantile(x,0.25)  # Compute the first quartile
			IQR(x)            
			fivenum(x)
			
			# code is committed
			\end{verbatim}
		\end{framed}
		
		
		
		
		%----------------------------------------------------------------%
		\section{Some Useful Operations}
		\subsection{Sampling}
		
		The \texttt{sample()} function.
		
		\subsection{Set Theory Operations}
		
		\subsection{Controlling Precision and Integerization}
		\begin{framed}
			\begin{verbatim}
			pi
			round(pi,3)
			round(pi,2)
			floor(pi)
			ceiling(pi)
			\end{verbatim}
		\end{framed}
		
		%----------------------------------------------------------------%
		
		\section{Important Introductory Topics}
		\subsection{The \texttt{head()} and \texttt{tail()} functions}
		\subsection{Randomly Generated Numbers}
		With $a$ and $b$ as the lower and upper bound of the continous uniform distribution.
		\[X \sim U(a,b)\]
		\subsection{The \texttt{as} and \texttt{is} families of functions}
		\subsection{The \texttt{apply} family of functions}
		\subsection{Writing your own function}
		
		
		%----------------------------------------------------------------%
		\section{Lists and Data Frames}
		\subsection{Lists}
		\subsection{Named Components}
		\subsection{Data Frames}
		\begin{framed}
			\begin{verbatim}
			framename = data.frame()
			\end{verbatim}
		\end{framed}
		%----------------------------------------------------------------%
		\section{Important Graphical Procedures}
		\begin{enumerate}
			\item Histograms
			\item Box-plots
			\item Scatter-plots
		\end{enumerate}
		
		
		%----------------------------------------------------------------%
		
		\subsection{Correlation  and Regression tests }
		\subsubsection{Correlation Coefficient}
		Strength of a linear relationship between $X$ and $Y$
		
		%\begin{framed}
		\begin{verbatim}
		M=1000
		CorrData=numeric(M)
		for (i in 1:M)
		{
		CorrData[i] = cor(rnorm(10),rnorm(10))
		}
		\end{verbatim}
		%\end{framed}
		The null hypothesis is that the correlation coefficient is zero. 
		
		The alternative hypothesis is that the correlation coefficients is greater than zero. 
		
		The slope and intercept estimates 
		
		These tests are given in the "Two Tailed" format. 
		The one tailed format compares a null hypothesis where the parameter of interest has a true value of less than or equalt to one versus an alternative hypothesis stating that it has a value greater than zero. 
		
		
		
		\newpage
		\section{Programming Paradigms}
		\subsection{While Loops}
		The while loop can be used if the number of iterations required is not known beforehand. For example, if we want to continue looping until a certain condition is met, a while loop is useful.
		
		The following is the syntax for a while loop:
		
		\begin{verbatim}
		while (condition){
		command
		command
		}
		\end{verbatim}
		The loop continues while \texttt{condition == TRUE}.
		
		
		Note: \texttt{sample()} takes a sample of the specified size (here just one) from a range of values (here integers 1 to 100).
		\begin{framed}
			\begin{verbatim}
			
			#initialise a counter to zero
			niter = 0		
			#initialize an empty vector
			numvec = numeric()
			
			
			num = sample(1:100, 1)
			
			#while loop
			while(num != 20)
			{
			num = sample(1:100, 1)
			niter = niter + 1
			numvec = c(numvec,num)
			}
			numvec
			niter
			
			\end{verbatim}
		\end{framed}
		
		
		\subsection{Nested Loops}
		
		\subsection{Sums of two dice rolls}
		\begin{framed}
			\begin{verbatim}
			#Set Up an Empty Matrix of 6 rows and 6 columns
			Dice = matrix(0,6,6)
			
			#Main Loop
			for(i in 1:6)
			{
			#Nested Loop
			for(j in 1:6)
			{
			Dice[i,j] = i+j
			}
			}		
			Dice   # Print your Results
			\end{verbatim}
		\end{framed}
		\subsection{Correlation Structure Example}
		
		
		\newpage
		\section{Correlation and Simple Regression Models}
		
		\subsection{Correlation}
		
		A correlation coefficient is a number between -1 and 1 which measures the degree to which two variables are linearly related. If there is perfect linear relationship with positive slope between the two variables, we have a correlation coefficient of 1; if there is positive correlation, whenever one variable has a high (low) value, so does the other.
		
		If there is a perfect linear relationship with negative slope between the two variables, we have a correlation coefficient of -1; if there is negative correlation, whenever one variable has a high (low) value, the other has a low (high) value.
		A correlation coefficient of 0 means that there is no linear relationship between the variables.
		
		We can determine the Pearson Correlation coefficient in R using the \texttt{cor()} command.
		To get a more complete statistical analysis, with formal tests, we can use the command \texttt{cor.test()}
		The interpretation of the output from the cor.test()procedure is very similar to procedures we have already encountered. The null hypothesis is that the correlation coefficient is equal to zero. This is equivalent to saying that there is no linear relationship between variables.
		
		
		\begin{framed}
			\begin{verbatim}
			C=c(0,2,4,6,8,10,12) 
			F=c(2.1,5.0,9.0,12.6,17.3,21.0,24.7)
			cor.test(C,F)
			\end{verbatim}
		\end{framed}
		\begin{verbatim}
		
		Pearson's product-moment correlation
		
		data:  C and F 
		t = 47.1967, df = 5, p-value = 8.066e-08
		alternative hypothesis: true correlation is not equal to 0 
		95 percent confidence interval:
		0.9920730 0.9998421 
		sample estimates:
		cor 
		0.9988796 
		\end{verbatim}
		
		
		\subsection{Spearman and Kendall Correlation}
		Spearman and Kendall correlations are both \textbf{\emph{rank correlations}}. 
		To implement Spearman and Kendall correlation, simply specify the type in the \texttt{method=" "} argument.
		\begin{verbatim}
		> cor(G,D)
		[1] 0.3167869
		>
		> cor(G,D,method="spearman")
		[1] 0.1785714
		>
		> cor(G,D,method="kendall")
		[1] 0.1428571
		> 
		\end{verbatim}
		The interpretation is very similar, but there are no confidence intervals for the estimates.
		
		\subsection{Fitting a Regression Model}
		A regression model is fitted using the \texttt{lm()} command.
		
		Consider the response variable $F$ and predictor variable $C$.
		\begin{framed}
			\begin{verbatim}
			C=c(0,2,4,6,8,10,12) 
			F=c(2.1,5.0,9.0,12.6,17.3,21.0,24.7)
			Fit1=lm(F~C)
			\end{verbatim}
		\end{framed}
		
		
		\subsection{Confidence and Prediction Intervals for Fitted Values} 
		
		Recall that a fitted value $\hat{Y}$ is a estimate for the response variable, as determined by a linear model. The difference between the observed value and the corresponding fitted value is known as the residual.
		
		The \textbf{\emph{residual standard error}} is the conditional standard deviation of the dependent variable Y given a value of the independent variable X. The calculation of this standard error follows from the definition of the residuals.
		
		The residual standard error is often called the root mean square error (RMSE), and is a measure of the differences between values predicted by a model or an estimator and the values actually observed from the thing being modelled or estimated.
		
		Since the residual standard error is a good measure of accuracy, it is ideal if it is small.
		
		\subsubsection{Prediction Intervals}
		In contrast to a confidence interval, which is concerned with estimating a population parameter, a prediction interval is concerned with estimating an individual value and is therefore a type of probability interval. 
		
		The complete standard error for a prediction interval is called the standard error of forecast, and it includes the uncertainty associated with the vertical “scatter” about the regression line plus the uncertainty associated with the position of the regression line value itself.
		
		
		
		
		
		
		
		
		
		\newpage
		%----------------------------------------------------------------------------------------------------------------------------%
		\section{Working with Categorical Data}
		\subsection{Chi-Square}
		
		The table below shows the relationship between gender and party identification in a US state.
		
		
		%	   & Democrat &	Independent & Republican & Total \\
		%Male   &	279	& 73  &	225 &	577 \\
		%Female &	165	& 47  & 191 &	403 \\
		%Total  &	444 & 120 &	416	&   980 \\
		
		Test for association between gender and party affiliation at two appropriate levels
		and comment on your results.
		
		Set out the null hypothesis that there is no association between method of computation
		and gender against the alternative, that there is. Be careful to get these the correct way
		round!
		
		H0: There is no association.
		H1: There is an association.
		
		Work out the expected values. For example, you should work out the expected value for
		the number of males who use no aids from the following: (95/195) × 22 = 10.7.
		
		
		\section{Probability Distributions}
		\subsection{Discrete Probability Distribution}
		
		
		The two most accessible discrete distributions are the binomial and \textbf{\emph{Poisson}} distributions
		
		
		
		
		
		
		
		
		
		
		
